{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Valuation with Nearest Neighbor Explainers\n",
    "\n",
    "This notebook explains how explainers of nearest-neighbor (NN) models can be used for Data Valuation, the task of evaluating the usefulness of individual training data points in classification problems.\n",
    "When explaining NN models, a game is defined by first choosing an explanation point $x_\\text{explain}$ and class $y_\\text{explain}$; the training data points $\\mathcal{D} := \\mathcal{X} \\times \\mathcal{Y}$ are the game's players, and the definition of the utility $\\nu(S)$ of a coalition $S \\subseteq \\mathcal{D}$ is based on the probability of the model predicting class $y_\\text{explain}$ on $x_\\text{explain}$ if it's training data were limited to $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is support for explaining the the `KNeighborsClassifier` model (with `'uniform'` or `'distance'` weights) and `RadiusNeighborsClassifier` model from the `scikit-learn` library.\n",
    "The algorithms are based on the publications from [Jia et al. (2019)](https://doi.org/10.48550/arXiv.1908.08619/), [Wang et al. (2024)](https://doi.org/10.48550/arXiv.1908.08619)\n",
    "and [Wang et al. (2023)](https://doi.org/10.48550/arXiv.2308.15709), respectively.\n",
    "\n",
    "Let's start by generating a synthetic classification datset and fitting a simple `KNeighborsClassifier` to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from plot_helpers import plot_datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "\n",
    "X_train, y_train = make_classification(\n",
    "    n_samples=30,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_clusters_per_class=1,\n",
    "    n_informative=2,\n",
    "    n_classes=2,\n",
    "    random_state=45,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plot_datasets(ax, X_train, y_train)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "x_explain = np.array([[-0.75, -0.4]])\n",
    "y_explain_pred = model.predict(x_explain)[0]\n",
    "print(f\"Prediction: class {y_explain_pred}\")\n",
    "\n",
    "y_explain_proba = model.predict_proba(x_explain)[0]\n",
    "print(f\"Prediction probabilities: {y_explain_proba}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `KNNExplainer` for Unweighted $k$-Nearest Neighbor Models\n",
    "\n",
    "To explain the prediction, we create an explainer for the model by passing it to the constructor of `Explainer`, which will automatically dispatch to the adequate subclass `KNNExplainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapiq import Explainer\n",
    "\n",
    "explainer = Explainer(model, class_index=y_explain_pred, max_order=1)\n",
    "print(type(explainer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we set `class_index=y_explain_pred`, since for now, we want to quantify the contribution of the training data to the class that was actually predicted. (We could also set a different class index if we wished to see how much the data points contribute to shifting the prediction towards another class.)\n",
    "\n",
    "Now we can get an explanation for the prediction we saw above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv = explainer.explain(x_explain)\n",
    "print(iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining Weighted $k$-Nearest Neighbor and Threshold Nearest Neighbor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are separate explainers for weighted $k$-NN and threshold NN models, which are selected automatically when an `Explainer` is instantiated with a corresponding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wknn_model = KNeighborsClassifier(n_neighbors=3, weights=\"distance\")\n",
    "wknn_model.fit(X_train, y_train)\n",
    "wknn_explainer = Explainer(wknn_model, max_order=1)\n",
    "print(type(wknn_explainer))\n",
    "\n",
    "tnn_model = RadiusNeighborsClassifier()\n",
    "tnn_model.fit(X_train, y_train)\n",
    "tnn_explainer = Explainer(tnn_model, max_order=1)\n",
    "print(type(tnn_explainer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They can be used just the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wknn_explainer.explain(x_explain))\n",
    "print(tnn_explainer.explain(x_explain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying corrupted training samples\n",
    "\n",
    "We can estimate the usefulness of each point of a training data set by calculating Shapley values for a set of test data points and averaging the results. This will allow us to identify potentially mislabeled data points.\n",
    "\n",
    "First, let's create a classification data set and split it into train and test sets. We will corrupt the training data by changing the class of a few randomly selected data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=100,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_clusters_per_class=1,\n",
    "    n_informative=2,\n",
    "    n_classes=2,\n",
    "    flip_y=0,\n",
    "    random_state=49,\n",
    "    class_sep=1.5,\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "y_train_corrupted = y_train.copy()\n",
    "n_corrupt = 7\n",
    "rng = np.random.default_rng(seed=43)\n",
    "corrupted = rng.choice(np.arange(X_train.shape[0]), size=n_corrupt, replace=False)\n",
    "# Since our only class indices are 0 and 1, this is a quick way to flip the class\n",
    "y_train_corrupted[corrupted] = 1 - y_train[corrupted]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plot_datasets(ax, X_train, y_train_corrupted, X_test, y_test)\n",
    "# Mark corrupted datapoints\n",
    "ax.scatter(\n",
    "    X_train[corrupted, 0],\n",
    "    X_train[corrupted, 1],\n",
    "    marker=\"o\",\n",
    "    edgecolors=\"#b1170c\",\n",
    "    facecolors=\"none\",\n",
    "    s=100,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the `KNNExplainer` to compute the training points' Shapley values based on the entire test dataset by averaging the Shapley values computed using each test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapiq.explainer.nn.iv_utils import interaction_values_to_array\n",
    "\n",
    "# Train the model with the corrupted training data\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train_corrupted)\n",
    "\n",
    "sv_test = np.zeros(X_train.shape[0], dtype=np.float64)\n",
    "\n",
    "for x_test_current, y_test_current in zip(X_test, y_test, strict=True):\n",
    "    explainer = Explainer(model, class_index=y_test_current, max_order=1)\n",
    "    iv = explainer.explain(x_test_current)\n",
    "    sv_current = interaction_values_to_array(iv)\n",
    "    sv_test += sv_current\n",
    "\n",
    "sv_test /= X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reasonably assume that the corrupted training data points will on average make the model's prediction worse, resulting in negative Shapley values. So let's filter out just those indices where the Shapley value is below zero and compare with our original array of corrupted indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Corrupted: {np.sort(corrupted)}\")  # Sort for easier comparison\n",
    "print(f\"Negative Shapley values: {np.where(sv_test < 0)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have identified the set corrupted samples almost exactly. The fact that the point with index 20 was missed, however, shows that this method is not failsafe but only an estimate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapiq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
