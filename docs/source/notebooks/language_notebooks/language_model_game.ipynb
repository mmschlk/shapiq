{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"3b000618e37afdb3\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"# Explaining a language model for sentiment analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook shows how we can use `shapiq` to explain the predictions of a language sentiment analysis model. For that, we will create a custom *game* that will be used for the explanation. The benchmark game resulting from this tutorial is available as `shapiq.games.SentimentClassificationGame`.\\n\",\n",
    "    \"\\n\",\n",
    "    \"First, we need to install the required packages next to `shapiq`. We will use a language model from the `transformers` library; specifically relying on `torch`.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"96756a5298128aed\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Install the required packages\\n\",\n",
    "    \"!pip install transformers torch\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"233a68eadd33ade3\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import the required libraries\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from transformers import pipeline\\n\",\n",
    "    \"\\n\",\n",
    "    \"import shapiq\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"shapiq version: {shapiq.__version__}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"45f9a6a38b3b0214\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Language model\\n\",\n",
    "    \"We will use a pre-trained BERT model for sentiment analysis. We will use the `transformers` library to load the model and tokenizer. We will use the `lvwerra/distilbert-imdb` model for this tutorial.\\n\",\n",
    "    \"\\n\",\n",
    "    \"The model predicts the sentiment of the sentence as **positive**. For this model (and other sentiment-analysis models), the output is a list of dictionaries, where each dictionary contains the `label` and the `score` of the sentiment. The label can be either `POSITIVE` or `NEGATIVE`. The score is the probability of the sentiment being positive or negative. The tokenized sentence contains the tokens of the sentence. The special tokens map contains the special tokens used by the model. We will need the `mask_token` later in the game.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 20,\n",
    "   \"id\": \"50f59cc77301eef0\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:08.828615Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:08.077616Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Device set to use mps:0\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Classifier output: [{'label': 'POSITIVE', 'score': 0.9951981902122498}]\\n\",\n",
    "      \"Tokenized sentence: {'input_ids': [101, 1045, 2293, 2023, 3185, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\\n\",\n",
    "      \"Special tokens: {'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\\n\",\n",
    "      \"Mask token id: 103\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Load the model and tokenizer\\n\",\n",
    "    \"classifier = pipeline(task=\\\"sentiment-analysis\\\", model=\\\"lvwerra/distilbert-imdb\\\")\\n\",\n",
    "    \"tokenizer = classifier.tokenizer\\n\",\n",
    "    \"\\n\",\n",
    "    \"test_sentence = \\\"I love this movie!\\\"\\n\",\n",
    "    \"print(f\\\"Classifier output: {classifier(test_sentence)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"tokenized_sentence = tokenizer(test_sentence)\\n\",\n",
    "    \"print(f\\\"Tokenized sentence: {tokenized_sentence}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"special_tokens = tokenizer.special_tokens_map\\n\",\n",
    "    \"print(f\\\"Special tokens: {tokenizer.special_tokens_map}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"mask_toke_id = tokenizer.mask_token_id\\n\",\n",
    "    \"print(f\\\"Mask token id: {mask_toke_id}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"25e75bdac10f7042\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"We can inspect the behavior of the model by checking the output of the classifier for different sentences and by decoding the tokenized sentences. The `tokenizer.decode` function can be used to decode the tokenized sentence. The `[CLS]` token is used to mark the beginning of the sentence, and the `[SEP]` token is used to mark the end of the sentence. Notice that also the `!` token is tokenized.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 21,\n",
    "   \"id\": \"c3b3b6f4193e7d73\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:15.176795Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:15.172168Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Decoded sentence: [CLS] i love this movie! [SEP]\\n\",\n",
    "      \"Decoded sentence: i love this movie! - Tokenized input: [1045 2293 2023 3185  999] - 5 tokens.\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Test the tokenizer\\n\",\n",
    "    \"decoded_sentence = tokenizer.decode(tokenized_sentence[\\\"input_ids\\\"])\\n\",\n",
    "    \"print(f\\\"Decoded sentence: {decoded_sentence}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Remove the start and end tokens\\n\",\n",
    "    \"tokenized_input = np.asarray(tokenizer(test_sentence)[\\\"input_ids\\\"][1:-1])\\n\",\n",
    "    \"decoded_sentence = tokenizer.decode(tokenized_input)\\n\",\n",
    "    \"print(\\n\",\n",
    "    \"    f\\\"Decoded sentence: {decoded_sentence} - Tokenized input: {tokenized_input} - {len(tokenized_input)} tokens.\\\"\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"97381c1da32a6c49\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"Since the start and end tokens are always present this information is not relevant for our explanation. To explain this classifier we need to model its behavior as a cooperative game.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"cca96f0af12688\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Treating the language model as a game with a value function\\n\",\n",
    "    \"For all Shapley-based feature attribution methods, we need to model the problem as a cooperative game. We need to define a **value function** that assigns a real-valued worth to each coalition of features. In this case, the features are the tokens of the sentence (without the `[CLS]` and `[SEP]` tokens). The value of the coalition is the sentiment score of the sentence with tokens that are not participating in the coalition `masked` or `removed`.\\n\",\n",
    "    \"\\n\",\n",
    "    \"A value function has the following formal definition:\\n\",\n",
    "    \"$$v: 2^N \\\\rightarrow \\\\mathbb{R}$$\\n\",\n",
    "    \"where $N$ is the set of features (tokens in our case). \\n\",\n",
    "    \"\\n\",\n",
    "    \"To be able to model `POSITIVE` and `NEGATIVE` sentiments, we need to map the output of the classifier to be in the range $[-1, 1]$. We can do this with the following function which accepts a list of input texts and returns a vector of the sentiment of the input texts.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 22,\n",
    "   \"id\": \"bce879ce457e9a98\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:21.617209Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:21.562026Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Model call: [ 0.99519819 -0.95526284]\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Define the model call function\\n\",\n",
    "    \"def model_call(input_texts: list[str]) -> np.ndarray[float]:\\n\",\n",
    "    \"    \\\"\\\"\\\"Calls the sentiment classification model with a list of texts.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        input_texts: A list of input texts.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        A vector of the sentiment of the input texts.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    outputs = classifier(input_texts)\\n\",\n",
    "    \"    outputs = [\\n\",\n",
    "    \"        output[\\\"score\\\"] * 1 if output[\\\"label\\\"] == \\\"POSITIVE\\\" else output[\\\"score\\\"] * -1\\n\",\n",
    "    \"        for output in outputs\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"    return np.array(outputs, dtype=float)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test the model call function\\n\",\n",
    "    \"print(f\\\"Model call: {model_call(['I love this movie!', 'I hate this movie!'])}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"ee183b3800498675\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"With this model call function, we can now define the value function. In our world the value function accepts one-hot-encoded numpy matrices denoting the coalitions.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 23,\n",
    "   \"id\": \"d176905292347ec1\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:26.712267Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:26.708314Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Empty coalition: [[False False False False False]]\\n\",\n",
    "      \"Full coalition: [[ True  True  True  True  True]]\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Show coalitions\\n\",\n",
    "    \"n_players = len(tokenized_sentence[\\\"input_ids\\\"]) - 2  # remove [CLS] and [SEP]\\n\",\n",
    "    \"\\n\",\n",
    "    \"empty_coalition = np.zeros((1, n_players), dtype=bool)  # empty coalition\\n\",\n",
    "    \"full_coalition = np.ones((1, n_players), dtype=bool)  # full coalition\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Empty coalition: {empty_coalition}\\\")\\n\",\n",
    "    \"print(f\\\"Full coalition: {full_coalition}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"bb8100b1a3fc09e3\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"With these coalitions we can now define the value function. However, for most algorithms it is important that the value function is normalized (also known as centered). This means that the value of the empty coalition is 0. We can achieve this by subtracting the value of the empty coalition from the value of the coalition. This is done in the `shapiq` library, but we can also do it here.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Formally, the normalized value function is defined as:\\n\",\n",
    "    \"$$v_0 := v(S) - v(\\\\emptyset)$$\\n\",\n",
    "    \"where $v(S)$ is the value of the coalition $S$ and $v(\\\\emptyset)$ is the value of the empty coalition.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 24,\n",
    "   \"id\": \"79a5c423622a0904\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:30.232296Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:30.229475Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define the value function\\n\",\n",
    "    \"def value_function(\\n\",\n",
    "    \"    coalitions: np.ndarray[bool], tokenized_input: np.ndarray[int], normalization_value: float = 0.0\\n\",\n",
    "    \") -> np.ndarray[float]:\\n\",\n",
    "    \"    \\\"\\\"\\\"Computes the value of the coalitions.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        coalitions: A numpy matrix of shape (n_coalitions, n_players).\\n\",\n",
    "    \"        tokenized_input: A numpy array of the tokenized input sentence.\\n\",\n",
    "    \"        normalization_value: The value of the empty coalition. Default is 0.0 (no normalization).\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        A vector of the value of the coalitions.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    texts = []\\n\",\n",
    "    \"    for coalition in coalitions:\\n\",\n",
    "    \"        tokenized_coalition = tokenized_input.copy()\\n\",\n",
    "    \"        # all tokens not in the coalition are set to mask_token_id\\n\",\n",
    "    \"        tokenized_coalition[~coalition] = mask_toke_id\\n\",\n",
    "    \"        coalition_text = tokenizer.decode(tokenized_coalition)\\n\",\n",
    "    \"        texts.append(coalition_text)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # get the sentiment of the texts (call the model as defined above)\\n\",\n",
    "    \"    sentiments = model_call(texts)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # normalize/center the value function\\n\",\n",
    "    \"    return sentiments - normalization_value\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"a8b971656158325b\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"We can test the value function without normalization. The output of the value function for the grand coalition (full coalition) should be the same as the output of the classifier. The output of the value function for the empty coalition is some bias value in the model which often is not zero.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 25,\n",
    "   \"id\": \"22b2201ca139c0d0\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:36.059205Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:35.998850Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Output of the classifier: [{'label': 'POSITIVE', 'score': 0.9951981902122498}]\\n\",\n",
    "      \"Value function for the full coalition: 0.9951981902122498\\n\",\n",
    "      \"Value function for the empty coalition: 0.5192136764526367\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Test the value function without normalization\\n\",\n",
    "    \"print(f\\\"Output of the classifier: {classifier(test_sentence)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\n\",\n",
    "    \"    f\\\"Value function for the full coalition: {value_function(full_coalition, tokenized_input=tokenized_input)[0]}\\\"\\n\",\n",
    "    \")\\n\",\n",
    "    \"print(\\n\",\n",
    "    \"    f\\\"Value function for the empty coalition: {value_function(empty_coalition, tokenized_input=tokenized_input)[0]}\\\"\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"ae20674fc899a202\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"If we normalize the value function, the output of the value function for the empty coalition should be zero.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 26,\n",
    "   \"id\": \"338e1ae439120652\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:38.518862Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:38.452386Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Value function for the full coalition: 0.47598451375961304\\n\",\n",
    "      \"Value function for the empty coalition: 0.0\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Test the value function with normalization\\n\",\n",
    "    \"normalization_value = float(value_function(empty_coalition, tokenized_input=tokenized_input)[0])\\n\",\n",
    "    \"print(\\n\",\n",
    "    \"    f\\\"Value function for the full coalition: {value_function(full_coalition, tokenized_input=tokenized_input, normalization_value=normalization_value)[0]}\\\"\\n\",\n",
    "    \")\\n\",\n",
    "    \"print(\\n\",\n",
    "    \"    f\\\"Value function for the empty coalition: {value_function(empty_coalition, tokenized_input=tokenized_input, normalization_value=normalization_value)[0]}\\\"\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"7be865dbf772ea6c\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"`shapiq` expects the game to be only dependent on the coalitions. For this we can write a small wrapper function:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 27,\n",
    "   \"id\": \"91e8b195226e1ecb\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:41.085429Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:41.031506Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Game for the full coalition: 0.47598451375961304\\n\",\n",
    "      \"Game for the empty coalition: 0.0\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Define the game function\\n\",\n",
    "    \"def game_fun(coalitions: np.ndarray[bool]) -> np.ndarray[float]:\\n\",\n",
    "    \"    \\\"\\\"\\\"Wrapper function for the value function.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        coalitions: A numpy matrix of shape (n_coalitions, n_players).\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        A vector of the value of the coalitions.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    return value_function(\\n\",\n",
    "    \"        coalitions, tokenized_input=tokenized_input, normalization_value=normalization_value\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test the game function\\n\",\n",
    "    \"print(f\\\"Game for the full coalition: {game_fun(full_coalition)[0]}\\\")\\n\",\n",
    "    \"print(f\\\"Game for the empty coalition: {game_fun(empty_coalition)[0]}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"5762eda66918ae03\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"We can use this callable already in `shapiq`, but we can also define it as a proper `Game` object, which comes with some additional functionality. Notice that the `value_function` function is now a method of the `SentimentClassificationGame` class and you do not have to worry about the normalization. This is done automatically by the `Game` class which also contains the `__call__` method meaning that this class is also callable.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 28,\n",
    "   \"id\": \"ea94eb7697abad0d\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:43.228217Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:43.159041Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Game for the full coalition: 0.47598451375961304\\n\",\n",
    "      \"Game for the empty coalition: 0.0\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"class SentimentClassificationGame(shapiq.Game):\\n\",\n",
    "    \"    \\\"\\\"\\\"The sentiment analysis classifier modeled as a cooperative game.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        classifier: The sentiment analysis classifier.\\n\",\n",
    "    \"        tokenizer: The tokenizer of the classifier.\\n\",\n",
    "    \"        test_sentence: The sentence to be explained.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __init__(self, classifier, tokenizer, test_sentence: str) -> None:\\n\",\n",
    "    \"        self.classifier = classifier\\n\",\n",
    "    \"        self.tokenizer = tokenizer\\n\",\n",
    "    \"        self.test_sentence = test_sentence\\n\",\n",
    "    \"        self.mask_token_id = tokenizer.mask_token_id\\n\",\n",
    "    \"        self.tokenized_input = np.asarray(tokenizer(test_sentence)[\\\"input_ids\\\"][1:-1])\\n\",\n",
    "    \"        self.n_players = len(self.tokenized_input)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        empty_coalition = np.zeros((1, len(self.tokenized_input)), dtype=bool)\\n\",\n",
    "    \"        self.normalization_value = float(self.value_function(empty_coalition)[0])\\n\",\n",
    "    \"        super().__init__(n_players=self.n_players, normalization_value=self.normalization_value)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def value_function(self, coalitions: np.ndarray[bool]) -> np.ndarray[float]:\\n\",\n",
    "    \"        \\\"\\\"\\\"Computes the value of the coalitions.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Args:\\n\",\n",
    "    \"            coalitions: A numpy matrix of shape (n_coalitions, n_players).\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Returns:\\n\",\n",
    "    \"            A vector of the value of the coalitions.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        texts = []\\n\",\n",
    "    \"        for coalition in coalitions:\\n\",\n",
    "    \"            tokenized_coalition = self.tokenized_input.copy()\\n\",\n",
    "    \"            # all tokens not in the coalition are set to mask_token_id\\n\",\n",
    "    \"            tokenized_coalition[~coalition] = self.mask_token_id\\n\",\n",
    "    \"            coalition_text = self.tokenizer.decode(tokenized_coalition)\\n\",\n",
    "    \"            texts.append(coalition_text)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # get the sentiment of the texts (call the model as defined above)\\n\",\n",
    "    \"        return self._model_call(texts)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _model_call(self, input_texts: list[str]) -> np.ndarray[float]:\\n\",\n",
    "    \"        \\\"\\\"\\\"Calls the sentiment classification model with a list of texts.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Args:\\n\",\n",
    "    \"            input_texts: A list of input texts.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Returns:\\n\",\n",
    "    \"            A vector of the sentiment of the input texts.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        outputs = self.classifier(input_texts)\\n\",\n",
    "    \"        outputs = [\\n\",\n",
    "    \"            output[\\\"score\\\"] * 1 if output[\\\"label\\\"] == \\\"POSITIVE\\\" else output[\\\"score\\\"] * -1\\n\",\n",
    "    \"            for output in outputs\\n\",\n",
    "    \"        ]\\n\",\n",
    "    \"        return np.array(outputs, dtype=float)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test SentimentClassificationGame\\n\",\n",
    "    \"game_class = SentimentClassificationGame(classifier, tokenizer, test_sentence)\\n\",\n",
    "    \"print(f\\\"Game for the full coalition: {game_class(full_coalition)[0]}\\\")\\n\",\n",
    "    \"print(f\\\"Game for the empty coalition: {game_class(empty_coalition)[0]}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"5a100294487e50fc\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Computing Shapley interactions\\n\",\n",
    "    \"We can now use the `game_fun` function or the `SentimentClassificationGame` class to compute the Shapley interactions with methods provided in `shapiq`.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 29,\n",
    "   \"id\": \"f62adc49538c8a79\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:46.920265Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:46.560454Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"{(): 0.0,\\n\",\n",
    "       \" (0,): 0.09466195971855056,\\n\",\n",
    "       \" (1,): 0.25196716824771664,\\n\",\n",
    "       \" (2,): 0.0685300282420717,\\n\",\n",
    "       \" (3,): 0.062281793911904096,\\n\",\n",
    "       \" (4,): 0.15022942865020356,\\n\",\n",
    "       \" (0, 1): -0.023901333187365998,\\n\",\n",
    "       \" (0, 2): -0.015578439625581331,\\n\",\n",
    "       \" (0, 3): 0.013715575352253404,\\n\",\n",
    "       \" (0, 4): -0.01258507319349111,\\n\",\n",
    "       \" (1, 2): 0.03777690850760815,\\n\",\n",
    "       \" (1, 3): -0.07309902775328235,\\n\",\n",
    "       \" (1, 4): -0.0557083696965391,\\n\",\n",
    "       \" (2, 3): 0.015661051009713458,\\n\",\n",
    "       \" (2, 4): -0.0608169041539291,\\n\",\n",
    "       \" (3, 4): 0.022849749426163614}\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 29,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Compute Shapley interactions with the ShapIQ approximator for the game function\\n\",\n",
    "    \"approximator = shapiq.KernelSHAPIQ(n=n_players, max_order=2, index=\\\"k-SII\\\")\\n\",\n",
    "    \"sii_values = approximator.approximate(budget=2**n_players, game=game_fun)\\n\",\n",
    "    \"sii_values.dict_values\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 30,\n",
    "   \"id\": \"7641d33a850cdd16\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:28:48.531320Z\",\n",
    "     \"start_time\": \"2025-10-07T17:28:48.185213Z\"\n",
    "    },\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"{(): 0.0,\\n\",\n",
    "       \" (0,): 0.09466195971855056,\\n\",\n",
    "       \" (1,): 0.25196716824771664,\\n\",\n",
    "       \" (2,): 0.0685300282420717,\\n\",\n",
    "       \" (3,): 0.062281793911904096,\\n\",\n",
    "       \" (4,): 0.15022942865020356,\\n\",\n",
    "       \" (0, 1): -0.023901333187365998,\\n\",\n",
    "       \" (0, 2): -0.015578439625581331,\\n\",\n",
    "       \" (0, 3): 0.013715575352253404,\\n\",\n",
    "       \" (0, 4): -0.01258507319349111,\\n\",\n",
    "       \" (1, 2): 0.03777690850760815,\\n\",\n",
    "       \" (1, 3): -0.07309902775328235,\\n\",\n",
    "       \" (1, 4): -0.0557083696965391,\\n\",\n",
    "       \" (2, 3): 0.015661051009713458,\\n\",\n",
    "       \" (2, 4): -0.0608169041539291,\\n\",\n",
    "       \" (3, 4): 0.022849749426163614}\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 30,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Compute Shapley interactions with the ShapIQ approximator for the game object\\n\",\n",
    "    \"approximator = shapiq.KernelSHAPIQ(n=game_class.n_players, max_order=2, index=\\\"k-SII\\\")\\n\",\n",
    "    \"sii_values = approximator.approximate(budget=2**game_class.n_players, game=game_class)\\n\",\n",
    "    \"sii_values.dict_values\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"ef3641f671c8616b\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Now let's say we want to do this for a much larger inputs. We can use the `shapiq.SPEX` approximator which is a sparse\\n\",\n",
    "    \"transform approximator. This approximator is much faster than the KernelSHAPIQ approximator when the number of\\n\",\n",
    "    \"players is large and can be used for larger inputs. Instead of computing all interactions it computes only the\\n\",\n",
    "    \"most important ones.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 31,\n",
    "   \"id\": \"ce6bc4d47530fa2b\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:34:18.159493Z\",\n",
    "     \"start_time\": \"2025-10-07T17:29:01.030509Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"There are a total of 175 players.\\n\",\n",
    "      \"Game for the full coalition: 0.47598451375961304\\n\",\n",
    "      \"Game for the empty coalition: 0.0\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"text = \\\"\\\"\\\"\\n\",\n",
    "    \"shapiq is a valuable Python library designed for Explainable AI (XAI), focusing specifically on approaches like\\n\",\n",
    "    \"Shapley values and their extensions. Its core strength lies in providing a unified framework to compute not only individual feature attributions but also sophisticated interaction indices (e.g., Shapley Interaction Index, Banzhaf Index). This allows users to gain deeper insights into how features collaborate or conflict within complex machine learning models, going beyond simple importance scores. A notable weakness stems from the inherent computational complexity of these game-theoretic measures. Calculating exact values, especially for higher-order interactions, is often infeasible, and even approximations can be computationally intensive and time-consuming, particularly for models with many features or large datasets. Despite this, shapiq remains a powerful tool for detailed model inspection.\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"big_game = SentimentClassificationGame(\\n\",\n",
    "    \"    classifier=classifier, tokenizer=tokenizer, test_sentence=text\\n\",\n",
    "    \")\\n\",\n",
    "    \"print(f\\\"There are a total of {big_game.n_players} players.\\\")\\n\",\n",
    "    \"# To speed up inference, run pipeline with gpu support. Takes ~10 minutes on Mac M1 with MPS.\\n\",\n",
    "    \"scalable_approximator = shapiq.SPEX(n=big_game.n_players, index=\\\"SII\\\", max_order=3, random_state=0)\\n\",\n",
    "    \"large_sii = scalable_approximator.approximate(budget=32000, game=big_game)\\n\",\n",
    "    \"print(f\\\"Game for the full coalition: {game_class(full_coalition)[0]}\\\")\\n\",\n",
    "    \"print(f\\\"Game for the empty coalition: {game_class(empty_coalition)[0]}\\\")\\n\",\n",
    "    \"interactions = list(large_sii.dict_values.items())\\n\",\n",
    "    \"interactions.sort(key=lambda x: abs(x[1]), reverse=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"e81434a652831817\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": \"`shapiq.SPEX` identifies interactions between the most sentiment-rich tokens in the paragraph (i.e. *powerful*, *valuable*, *weakness*)\"\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 32,\n",
    "   \"id\": \"a09121f781d9be77\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:34:18.174216Z\",\n",
    "     \"start_time\": \"2025-10-07T17:34:18.171782Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Tokens: ['powerful'], Value: 0.043\\n\",\n",
    "      \"Tokens: ['valuable', 'powerful'], Value: -0.031\\n\",\n",
    "      \"Tokens: ['weakness', 'powerful'], Value: 0.028\\n\",\n",
    "      \"Tokens: ['valuable'], Value: 0.025\\n\",\n",
    "      \"Tokens: ['weakness'], Value: -0.022\\n\",\n",
    "      \"Tokens: ['consuming', 'powerful'], Value: 0.018\\n\",\n",
    "      \"Tokens: ['valuable', 'weakness'], Value: 0.018\\n\",\n",
    "      \"Tokens: ['remains'], Value: 0.016\\n\",\n",
    "      \"Tokens: ['remains', 'powerful'], Value: -0.016\\n\",\n",
    "      \"Tokens: ['insights', 'powerful'], Value: -0.016\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"for inter, value in interactions[:10]:\\n\",\n",
    "    \"    tokens = [big_game.tokenizer.decode(big_game.tokenized_input[idx]) for idx in inter]\\n\",\n",
    "    \"    print(f\\\"Tokens: {tokens}, Value: {value:.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"8c395685ee2198dd\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": \"The `shapiq.ProxySPEX` approximator reduces the number of inferences needed by an order of magnitude.\"\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 33,\n",
    "   \"id\": \"13d938501ed5c19f\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-07T17:35:07.040543Z\",\n",
    "     \"start_time\": \"2025-10-07T17:34:18.258725Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Tokens: ['powerful'], Value: 0.058\\n\",\n",
    "      \"Tokens: ['weakness', 'powerful'], Value: 0.030\\n\",\n",
    "      \"Tokens: ['weakness'], Value: -0.030\\n\",\n",
    "      \"Tokens: ['valuable', 'powerful'], Value: -0.024\\n\",\n",
    "      \"Tokens: ['valuable'], Value: 0.023\\n\",\n",
    "      \"Tokens: ['focusing', 'calculating', 'powerful'], Value: -0.022\\n\",\n",
    "      \"Tokens: ['providing', 'a', 'powerful'], Value: 0.022\\n\",\n",
    "      \"Tokens: ['a', 'unified', 'powerful'], Value: 0.021\\n\",\n",
    "      \"Tokens: ['focusing', 'weakness', 'powerful'], Value: -0.019\\n\",\n",
    "      \"Tokens: ['valuable', 'insights', 'powerful'], Value: 0.018\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"scalable_approximator = shapiq.ProxySPEX(\\n\",\n",
    "    \"    n=big_game.n_players, index=\\\"SII\\\", max_order=3, random_state=0\\n\",\n",
    "    \")\\n\",\n",
    "    \"large_sii = scalable_approximator.approximate(budget=3200, game=big_game)\\n\",\n",
    "    \"interactions = list(large_sii.dict_values.items())\\n\",\n",
    "    \"interactions.sort(key=lambda x: abs(x[1]), reverse=True)\\n\",\n",
    "    \"for inter, value in interactions[:10]:\\n\",\n",
    "    \"    tokens = [big_game.tokenizer.decode(big_game.tokenized_input[idx]) for idx in inter]\\n\",\n",
    "    \"    print(f\\\"Tokens: {tokens}, Value: {value:.3f}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.11.9\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "36136981ffec1102"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
