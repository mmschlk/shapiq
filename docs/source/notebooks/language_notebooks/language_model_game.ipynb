{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b000618e37afdb3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Explaining a language model for sentiment analysis\n",
    "\n",
    "This notebook shows how we can use `shapiq` to explain the predictions of a language sentiment analysis model. For that, we will create a custom *game* that will be used for the explanation. The benchmark game resulting from this tutorial is available as `shapiq.games.SentimentClassificationGame`.\n",
    "\n",
    "First, we need to install the required packages next to `shapiq`. We will use a language model from the `transformers` library; specifically relying on `torch`."
   ]
  },
  {
   "cell_type": "code",
   "id": "96756a5298128aed",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:53.857295Z",
     "start_time": "2024-11-07T15:12:52.373920Z"
    }
   },
   "source": [
    "# Install the required packages\n",
    "!pip install transformers torch"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: torch in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from transformers) (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: colorama in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\1_workspaces\\1_phd_projects\\shapiq\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "233a68eadd33ade3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:53.873300Z",
     "start_time": "2024-11-07T15:12:53.859302Z"
    }
   },
   "source": [
    "# Import the required libraries\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import shapiq\n",
    "\n",
    "shapiq.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "45f9a6a38b3b0214",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Language model\n",
    "We will use a pre-trained BERT model for sentiment analysis. We will use the `transformers` library to load the model and tokenizer. We will use the `lvwerra/distilbert-imdb` model for this tutorial.\n",
    "\n",
    "The model predicts the sentiment of the sentence as **positive**. For this model (and other sentiment-analysis models), the output is a list of dictionaries, where each dictionary contains the `label` and the `score` of the sentiment. The label can be either `POSITIVE` or `NEGATIVE`. The score is the probability of the sentiment being positive or negative. The tokenized sentence contains the tokens of the sentence. The special tokens map contains the special tokens used by the model. We will need the `mask_token` later in the game."
   ]
  },
  {
   "cell_type": "code",
   "id": "50f59cc77301eef0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:55.030094Z",
     "start_time": "2024-11-07T15:12:53.876296Z"
    }
   },
   "source": [
    "# Load the model and tokenizer\n",
    "classifier = pipeline(task=\"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\")\n",
    "tokenizer = classifier.tokenizer\n",
    "\n",
    "test_sentence = \"I love this movie!\"\n",
    "print(f\"Classifier output: {classifier(test_sentence)}\")\n",
    "\n",
    "tokenized_sentence = tokenizer(test_sentence)\n",
    "print(f\"Tokenized sentence: {tokenized_sentence}\")\n",
    "\n",
    "special_tokens = tokenizer.special_tokens_map\n",
    "print(f\"Special tokens: {tokenizer.special_tokens_map}\")\n",
    "\n",
    "mask_toke_id = tokenizer.mask_token_id\n",
    "print(f\"Mask token id: {mask_toke_id}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\1_Workspaces\\1_Phd_Projects\\shapiq\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier output: [{'label': 'POSITIVE', 'score': 0.9951981902122498}]\n",
      "Tokenized sentence: {'input_ids': [101, 1045, 2293, 2023, 3185, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n",
      "Special tokens: {'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\n",
      "Mask token id: 103\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "25e75bdac10f7042",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can inspect the behavior of the model by checking the output of the classifier for different sentences and by decoding the tokenized sentences. The `tokenizer.decode` function can be used to decode the tokenized sentence. The `[CLS]` token is used to mark the beginning of the sentence, and the `[SEP]` token is used to mark the end of the sentence. Notice that also the `!` token is tokenized."
   ]
  },
  {
   "cell_type": "code",
   "id": "c3b3b6f4193e7d73",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:55.045636Z",
     "start_time": "2024-11-07T15:12:55.033094Z"
    }
   },
   "source": [
    "# Test the tokenizer\n",
    "decoded_sentence = tokenizer.decode(tokenized_sentence[\"input_ids\"])\n",
    "print(f\"Decoded sentence: {decoded_sentence}\")\n",
    "\n",
    "# Remove the start and end tokens\n",
    "tokenized_input = np.asarray(tokenizer(test_sentence)[\"input_ids\"][1:-1])\n",
    "decoded_sentence = tokenizer.decode(tokenized_input)\n",
    "print(\n",
    "    f\"Decoded sentence: {decoded_sentence} - Tokenized input: {tokenized_input} - {len(tokenized_input)} tokens.\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sentence: [CLS] i love this movie! [SEP]\n",
      "Decoded sentence: i love this movie! - Tokenized input: [1045 2293 2023 3185  999] - 5 tokens.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "97381c1da32a6c49",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Since the start and end tokens are always present this information is not relevant for our explanation. To explain this classifier we need to model its behavior as a cooperative game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca96f0af12688",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Treating the language model as a game with a value function\n",
    "For all Shapley-based feature attribution methods, we need to model the problem as a cooperative game. We need to define a **value function** that assigns a real-valued worth to each coalition of features. In this case, the features are the tokens of the sentence (without the `[CLS]` and `[SEP]` tokens). The value of the coalition is the sentiment score of the sentence with tokens that are not participating in the coalition `masked` or `removed`.\n",
    "\n",
    "A value function has the following formal definition:\n",
    "$$v: 2^N \\rightarrow \\mathbb{R}$$\n",
    "where $N$ is the set of features (tokens in our case). \n",
    "\n",
    "To be able to model `POSITIVE` and `NEGATIVE` sentiments, we need to map the output of the classifier to be in the range $[-1, 1]$. We can do this with the following function which accepts a list of input texts and returns a vector of the sentiment of the input texts.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "bce879ce457e9a98",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:55.170942Z",
     "start_time": "2024-11-07T15:12:55.046626Z"
    }
   },
   "source": [
    "# Define the model call function\n",
    "def model_call(input_texts: list[str]) -> np.ndarray[float]:\n",
    "    \"\"\"Calls the sentiment classification model with a list of texts.\n",
    "\n",
    "    Args:\n",
    "        input_texts: A list of input texts.\n",
    "\n",
    "    Returns:\n",
    "        A vector of the sentiment of the input texts.\n",
    "    \"\"\"\n",
    "    outputs = classifier(input_texts)\n",
    "    outputs = [\n",
    "        output[\"score\"] * 1 if output[\"label\"] == \"POSITIVE\" else output[\"score\"] * -1\n",
    "        for output in outputs\n",
    "    ]\n",
    "    sentiments = np.array(outputs, dtype=float)\n",
    "\n",
    "    return sentiments\n",
    "\n",
    "\n",
    "# Test the model call function\n",
    "print(f\"Model call: {model_call(['I love this movie!', 'I hate this movie!'])}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model call: [ 0.99519819 -0.95526284]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "ee183b3800498675",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With this model call function, we can now define the value function. In our world the value function accepts one-hot-encoded numpy matrices denoting the coalitions."
   ]
  },
  {
   "cell_type": "code",
   "id": "d176905292347ec1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:55.186860Z",
     "start_time": "2024-11-07T15:12:55.171942Z"
    }
   },
   "source": [
    "# Show coalitions\n",
    "n_players = len(tokenized_sentence[\"input_ids\"]) - 2  # remove [CLS] and [SEP]\n",
    "\n",
    "empty_coalition = np.zeros((1, n_players), dtype=bool)  # empty coalition\n",
    "full_coalition = np.ones((1, n_players), dtype=bool)  # full coalition\n",
    "\n",
    "print(f\"Empty coalition: {empty_coalition}\")\n",
    "print(f\"Full coalition: {full_coalition}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty coalition: [[False False False False False]]\n",
      "Full coalition: [[ True  True  True  True  True]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "bb8100b1a3fc09e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With these coalitions we can now define the value function. However, for most algorithms it is important that the value function is normalized (also known as centered). This means that the value of the empty coalition is 0. We can achieve this by subtracting the value of the empty coalition from the value of the coalition. This is done in the `shapiq` library, but we can also do it here.\n",
    "\n",
    "Formally, the normalized value function is defined as:\n",
    "$$v_0 := v(S) - v(\\emptyset)$$\n",
    "where $v(S)$ is the value of the coalition $S$ and $v(\\emptyset)$ is the value of the empty coalition."
   ]
  },
  {
   "cell_type": "code",
   "id": "79a5c423622a0904",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:55.202766Z",
     "start_time": "2024-11-07T15:12:55.187873Z"
    }
   },
   "source": [
    "# Define the value function\n",
    "def value_function(\n",
    "    coalitions: np.ndarray[bool], tokenized_input: np.ndarray[int], normalization_value: float = 0.0\n",
    ") -> np.ndarray[float]:\n",
    "    \"\"\"Computes the value of the coalitions.\n",
    "\n",
    "    Args:\n",
    "        coalitions: A numpy matrix of shape (n_coalitions, n_players).\n",
    "        tokenized_input: A numpy array of the tokenized input sentence.\n",
    "        normalization_value: The value of the empty coalition. Default is 0.0 (no normalization).\n",
    "\n",
    "    Returns:\n",
    "        A vector of the value of the coalitions.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    for coalition in coalitions:\n",
    "        tokenized_coalition = tokenized_input.copy()\n",
    "        # all tokens not in the coalition are set to mask_token_id\n",
    "        tokenized_coalition[~coalition] = mask_toke_id\n",
    "        coalition_text = tokenizer.decode(tokenized_coalition)\n",
    "        texts.append(coalition_text)\n",
    "\n",
    "    # get the sentiment of the texts (call the model as defined above)\n",
    "    sentiments = model_call(texts)\n",
    "\n",
    "    # normalize/center the value function\n",
    "    normalized_sentiments = sentiments - normalization_value\n",
    "\n",
    "    return normalized_sentiments"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "a8b971656158325b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can test the value function without normalization. The output of the value function for the grand coalition (full coalition) should be the same as the output of the classifier. The output of the value function for the empty coalition is some bias value in the model which often is not zero."
   ]
  },
  {
   "cell_type": "code",
   "id": "22b2201ca139c0d0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:55.361962Z",
     "start_time": "2024-11-07T15:12:55.205760Z"
    }
   },
   "source": [
    "# Test the value function without normalization\n",
    "print(f\"Output of the classifier: {classifier(test_sentence)}\")\n",
    "\n",
    "print(\n",
    "    f\"Value function for the full coalition: {value_function(full_coalition, tokenized_input=tokenized_input)[0]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Value function for the empty coalition: {value_function(empty_coalition, tokenized_input=tokenized_input)[0]}\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the classifier: [{'label': 'POSITIVE', 'score': 0.9951981902122498}]\n",
      "Value function for the full coalition: 0.9951981902122498\n",
      "Value function for the empty coalition: 0.5192136764526367\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "ae20674fc899a202",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If we normalize the value function, the output of the value function for the empty coalition should be zero."
   ]
  },
  {
   "cell_type": "code",
   "id": "338e1ae439120652",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:55.531455Z",
     "start_time": "2024-11-07T15:12:55.364891Z"
    }
   },
   "source": [
    "# Test the value function with normalization\n",
    "normalization_value = float(value_function(empty_coalition, tokenized_input=tokenized_input)[0])\n",
    "print(\n",
    "    f\"Value function for the full coalition: {value_function(full_coalition, tokenized_input=tokenized_input, normalization_value=normalization_value)[0]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Value function for the empty coalition: {value_function(empty_coalition, tokenized_input=tokenized_input, normalization_value=normalization_value)[0]}\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value function for the full coalition: 0.47598451375961304\n",
      "Value function for the empty coalition: 0.0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "7be865dbf772ea6c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`shapiq` expects the game to be only dependent on the coalitions. For this we can write a small wrapper function:"
   ]
  },
  {
   "cell_type": "code",
   "id": "91e8b195226e1ecb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:55.640446Z",
     "start_time": "2024-11-07T15:12:55.534458Z"
    }
   },
   "source": [
    "# Define the game function\n",
    "def game_fun(coalitions: np.ndarray[bool]) -> np.ndarray[float]:\n",
    "    \"\"\"Wrapper function for the value function.\n",
    "\n",
    "    Args:\n",
    "        coalitions: A numpy matrix of shape (n_coalitions, n_players).\n",
    "\n",
    "    Returns:\n",
    "        A vector of the value of the coalitions.\n",
    "    \"\"\"\n",
    "    return value_function(\n",
    "        coalitions, tokenized_input=tokenized_input, normalization_value=normalization_value\n",
    "    )\n",
    "\n",
    "\n",
    "# Test the game function\n",
    "print(f\"Game for the full coalition: {game_fun(full_coalition)[0]}\")\n",
    "print(f\"Game for the empty coalition: {game_fun(empty_coalition)[0]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game for the full coalition: 0.47598451375961304\n",
      "Game for the empty coalition: 0.0\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "5762eda66918ae03",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can use this callable already in `shapiq`, but we can also define it as a proper `Game` object, which comes with some additional functionality. Notice that the `value_function` function is now a method of the `SentimentClassificationGame` class and you do not have to worry about the normalization. This is done automatically by the `Game` class which also contains the `__call__` method meaning that this class is also callable."
   ]
  },
  {
   "cell_type": "code",
   "id": "ea94eb7697abad0d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:55.799060Z",
     "start_time": "2024-11-07T15:12:55.642440Z"
    }
   },
   "source": [
    "class SentimentClassificationGame(shapiq.Game):\n",
    "    \"\"\"The sentiment analysis classifier modeled as a cooperative game.\n",
    "\n",
    "    Args:\n",
    "        classifier: The sentiment analysis classifier.\n",
    "        tokenizer: The tokenizer of the classifier.\n",
    "        test_sentence: The sentence to be explained.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classifier, tokenizer, test_sentence):\n",
    "        self.classifier = classifier\n",
    "        self.tokenizer = tokenizer\n",
    "        self.test_sentence = test_sentence\n",
    "        self.mask_token_id = tokenizer.mask_token_id\n",
    "        self.tokenized_input = np.asarray(tokenizer(test_sentence)[\"input_ids\"][1:-1])\n",
    "        self.n_players = len(self.tokenized_input)\n",
    "\n",
    "        empty_coalition = np.zeros((1, len(self.tokenized_input)), dtype=bool)\n",
    "        self.normalization_value = float(self.value_function(empty_coalition)[0])\n",
    "        super().__init__(n_players=self.n_players, normalization_value=self.normalization_value)\n",
    "\n",
    "    def value_function(self, coalitions: np.ndarray[bool]) -> np.ndarray[float]:\n",
    "        \"\"\"Computes the value of the coalitions.\n",
    "\n",
    "        Args:\n",
    "            coalitions: A numpy matrix of shape (n_coalitions, n_players).\n",
    "\n",
    "        Returns:\n",
    "            A vector of the value of the coalitions.\n",
    "        \"\"\"\n",
    "        texts = []\n",
    "        for coalition in coalitions:\n",
    "            tokenized_coalition = self.tokenized_input.copy()\n",
    "            # all tokens not in the coalition are set to mask_token_id\n",
    "            tokenized_coalition[~coalition] = self.mask_token_id\n",
    "            coalition_text = self.tokenizer.decode(tokenized_coalition)\n",
    "            texts.append(coalition_text)\n",
    "\n",
    "        # get the sentiment of the texts (call the model as defined above)\n",
    "        sentiments = self._model_call(texts)\n",
    "\n",
    "        return sentiments\n",
    "\n",
    "    def _model_call(self, input_texts: list[str]) -> np.ndarray[float]:\n",
    "        \"\"\"Calls the sentiment classification model with a list of texts.\n",
    "\n",
    "        Args:\n",
    "            input_texts: A list of input texts.\n",
    "\n",
    "        Returns:\n",
    "            A vector of the sentiment of the input texts.\n",
    "        \"\"\"\n",
    "        outputs = self.classifier(input_texts)\n",
    "        outputs = [\n",
    "            output[\"score\"] * 1 if output[\"label\"] == \"POSITIVE\" else output[\"score\"] * -1\n",
    "            for output in outputs\n",
    "        ]\n",
    "        sentiments = np.array(outputs, dtype=float)\n",
    "\n",
    "        return sentiments\n",
    "\n",
    "\n",
    "# Test SentimentClassificationGame\n",
    "game_class = SentimentClassificationGame(classifier, tokenizer, test_sentence)\n",
    "print(f\"Game for the full coalition: {game_class(full_coalition)[0]}\")\n",
    "print(f\"Game for the empty coalition: {game_class(empty_coalition)[0]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game for the full coalition: 0.47598451375961304\n",
      "Game for the empty coalition: 0.0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "5a100294487e50fc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Computing Shapley interactions\n",
    "We can now use the `game_fun` function or the `SentimentClassificationGame` class to compute the Shapley interactions with methods provided in `shapiq`."
   ]
  },
  {
   "cell_type": "code",
   "id": "f62adc49538c8a79",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:57.300122Z",
     "start_time": "2024-11-07T15:12:55.801062Z"
    }
   },
   "source": [
    "# Compute Shapley interactions with the ShapIQ approximator for the game function\n",
    "approximator = shapiq.KernelSHAPIQ(n=n_players, max_order=2, index=\"k-SII\")\n",
    "sii_values = approximator.approximate(budget=2**n_players, game=game_fun)\n",
    "sii_values.dict_values"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(): 0.0,\n",
       " (0,): 0.09466196894645686,\n",
       " (1,): 0.2519671499729157,\n",
       " (2,): 0.06853009064992265,\n",
       " (3,): 0.06228183011213936,\n",
       " (4,): 0.15022933781147002,\n",
       " (0, 1): -0.02390133341153461,\n",
       " (0, 2): -0.015578468640645306,\n",
       " (0, 3): 0.013715575138727829,\n",
       " (0, 4): -0.0125850439071655,\n",
       " (1, 2): 0.03777685761451723,\n",
       " (1, 3): -0.07309910655021665,\n",
       " (1, 4): -0.055708358685175596,\n",
       " (2, 3): 0.015661031007766717,\n",
       " (2, 4): -0.06081686417261759,\n",
       " (3, 4): 0.02284984787305196}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "7641d33a850cdd16",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T15:12:58.639436Z",
     "start_time": "2024-11-07T15:12:57.302126Z"
    }
   },
   "source": [
    "# Compute Shapley interactions with the ShapIQ approximator for the game object\n",
    "approximator = shapiq.KernelSHAPIQ(n=game_class.n_players, max_order=2, index=\"k-SII\")\n",
    "sii_values = approximator.approximate(budget=2**game_class.n_players, game=game_class)\n",
    "sii_values.dict_values"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(): 0.0,\n",
       " (0,): 0.09466196894645686,\n",
       " (1,): 0.2519671499729157,\n",
       " (2,): 0.06853009064992265,\n",
       " (3,): 0.06228183011213936,\n",
       " (4,): 0.15022933781147002,\n",
       " (0, 1): -0.02390133341153461,\n",
       " (0, 2): -0.015578468640645306,\n",
       " (0, 3): 0.013715575138727829,\n",
       " (0, 4): -0.0125850439071655,\n",
       " (1, 2): 0.03777685761451723,\n",
       " (1, 3): -0.07309910655021665,\n",
       " (1, 4): -0.055708358685175596,\n",
       " (2, 3): 0.015661031007766717,\n",
       " (2, 4): -0.06081686417261759,\n",
       " (3, 4): 0.02284984787305196}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
