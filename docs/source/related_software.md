# ðŸ’» Related Software:

`shapiq` is a Library for computing Shapley Interactions and Shapley Values
for Machine Learning {cite:p}`Muschalik.2024b`. The following table contains a list of related software:

| Software       | Citation                  | Description                                                                                                                                                       |
|----------------|---------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `shapiq`       | {cite:p}`Muschalik.2024b` | This Python library for interpreting machine learning models with general game-theoretic concpts such as Shapley interactions, Shapley values, or Banzhaf values. |
| `shap`         | {cite:p}`Lundberg.2017`   | A Python library for interpreting machine learning models, including Shapley values.                                                                              |
| `OpenXAI`      | {cite:p}`Agarwal.2022`    | A benchmark suite for Explainable AI                                                                                                                              |
| `iNNvestigate` | {cite:p}`Alber.2019`      | An Interpretability Toolkit for Neural Networks                                                                                                                   |
| `aix360`       | {cite:p}`Arya.2020`       | An Extensible Toolkit for Understanding Data and Machine Learning Models                                                                                          |
| `dalex`        | {cite:p}`Baniecki.2021`   | Responsible Machine Learning with Interactive Explainability and Fairness in Python                                                                               |
| `openml`       | {cite:p}`Bischl.2021`     | A general purpose Benchmarking Suites                                                                                                                             |
| `quantus`      | {cite:p}`Hedstrom.2023`   | An Explainable AI Toolkit for Responsible Evaluation of Neural Network Explanations and Beyond                                                                    |
| `OpenDataVal`  | {cite:p}`Jiang.2023`      | A a Unified Benchmark for Data Valuation                                                                                                                          |
| `alibi`        | {cite:p}`Klaise.2021`     | General Algorithms for Explaining Machine Learning Models                                                                                                         |
| `captum`       | {cite:p}`Kokhlikyan.2020` | A unified and generic model interpretability library for PyTorch                                                                                                  |
| `XAI-bench`    | {cite:p}`Liu.2021`        | Synthetic Benchmarks for Scientific Research in Explainable Machine Learning                                                                                      |
| `M4`           | {cite:p}`Li.2023`         | A Unified XAI Benchmark for Faithfulness Evaluation of Feature Attribution Methods across Metrics, Modalities and Models                                          |
|                | {cite:p}`Olsen.2023`      | A comparative study of methods for estimating model-agnostic Shapley value explanations                                                                           |
